{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "\"\"\"\n",
    "Load Data\n",
    "\"\"\"\n",
    "def load_data():\n",
    "    data_path = \"movie/processed_ratings.dat\"\n",
    "    user_ratings = defaultdict(set)\n",
    "    max_uid = -1\n",
    "    max_iid = -1\n",
    "    with open(data_path, 'r', encoding='utf16') as f:\n",
    "        for line in f:\n",
    "            linetuple = line.strip().split(\"::\")\n",
    "            u = int(linetuple[0])\n",
    "            i = int(linetuple[1])\n",
    "            user_ratings[u].add(i)\n",
    "            max_uid = max(u, max_uid)\n",
    "            max_iid = max(i, max_iid)\n",
    "    \n",
    "    return max_uid, max_iid, user_ratings\n",
    "\n",
    "num_user, num_item, user_ratings = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of User : 6040\n",
      "number of Item : 3706\n",
      "number of raing : 1000209\n"
     ]
    }
   ],
   "source": [
    "print(\"number of User : %d\"%num_user)\n",
    "print(\"number of Item : %d\"%num_item)\n",
    "print(\"number of raing : %d\"%sum([len(x) for x in user_ratings.values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split Data by Train and Test\n",
    "\"\"\"\n",
    "\n",
    "def generate_test(user_ratings):\n",
    "    \n",
    "    user_test = dict()\n",
    "    for u, item_set in user_ratings.items():\n",
    "        user_test[u] = random.sample(item_set, 1)[0]\n",
    "    return user_test\n",
    "\n",
    "def train_batch(user_ratings, test_ratings, num_item, batch_size):\n",
    "\n",
    "    # Uniform sampling train data (user, item_rated(pos), item_not_rated)(neg)).\n",
    "    s = []\n",
    "    for b in range(batch_size):\n",
    "        u = random.sample(user_ratings.keys(), 1)[0]\n",
    "        i = random.sample(user_ratings[u], 1)[0]\n",
    "        # Only the rating values not found in the test data are sampled for train data.\n",
    "        while i == test_ratings[u]:\n",
    "            i = random.sample(user_ratings[u], 1)[0]\n",
    "        # Only the values that not rated by user.\n",
    "        j = random.randint(1, num_item)\n",
    "        while j in user_ratings[u]:\n",
    "            j = random.randint(1, num_item)\n",
    "        s.append([u, i, j]) # Train data sample\n",
    "    train = np.array(s)\n",
    "    \n",
    "    return train\n",
    "\n",
    "\n",
    "def test_batch(user_ratings, test_ratings, num_item):\n",
    "\n",
    "    for u in user_ratings.keys():\n",
    "        s = []\n",
    "        neg_item_list = []\n",
    "        i = test_ratings[u]\n",
    "        cnt = 0\n",
    "        while cnt < 100:\n",
    "            j = random.choice(range(1, num_item + 1))\n",
    "            if j not in neg_item_list and j not in user_ratings[u]:\n",
    "                s.append([u, i, j])\n",
    "                neg_item_list.append(j)\n",
    "                cnt += 1\n",
    "        yield np.array(s), [u, i, neg_item_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "BPR\n",
    "\"\"\"\n",
    "class BPR(nn.Module):\n",
    "    def __init__(self, num_user, num_item, hidden_size):\n",
    "        super(BPR, self).__init__()\n",
    "        \n",
    "        self.num_user = num_user\n",
    "        self.num_item = num_item\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.user_embedding = nn.Embedding(num_user, hidden_size)\n",
    "        self.item_embedding = nn.Embedding(num_item, hidden_size)\n",
    "        self.item_bias = nn.Parameter(torch.zeros(num_item+1))\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    def Embedding(num_embeddings, embedding_dim, std=0.1):\n",
    "        emb = nn.Embedding(num_embeddings+1, embedding_dim)\n",
    "        emb.weight.data.normal_(0, std)\n",
    "        emb.weight.grad\n",
    "\n",
    "        return emb\n",
    "    \n",
    "    def forward(self, input):\n",
    "        u = input[:,0]\n",
    "        i = input[:,1]\n",
    "        j = input[:,2]\n",
    "        \n",
    "        u_emb = self.user_embedding(u)\n",
    "        i_emb = self.item_embedding(i)\n",
    "        i_b = self.item_bias[i]\n",
    "        j_emb = self.item_embedding(j)\n",
    "        j_b = self.item_bias[j]\n",
    "        \n",
    "        # Matrix Factorization predict: u_i > u_j\n",
    "        x = i_b - j_b + torch.sum(torch.mul(u_emb, (i_emb - j_emb)), 1)\n",
    "\n",
    "        l2_norm = torch.norm(torch.cat([u_emb, i_emb, j_emb]), 2)\n",
    "        l2_norm = torch.pow(l2_norm, 2)\n",
    "        \n",
    "        loss = 0.0001 * l2_norm - torch.mean(torch.log(self.sigmoid(x)))\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def evalu(self, input):\n",
    "        u = input[:,0]\n",
    "        i = input[:,1]\n",
    "        j = input[:,2]\n",
    "        \n",
    "        u_emb = self.user_embedding(u)\n",
    "        i_emb = self.item_embedding(i)\n",
    "        i_b = self.item_bias[i]\n",
    "        j_emb = self.item_embedding(j)\n",
    "        j_b = self.item_bias[j]\n",
    "        \n",
    "        # Matrix Factorization predict: u_i > u_j\n",
    "        x = i_b - j_b + torch.sum(torch.mul(u_emb, (i_emb - j_emb)), 1)\n",
    "        \n",
    "        \n",
    "        pred = torch.max(x,torch.zeros(1).cuda())\n",
    "        mf_auc = torch.mean(pred)\n",
    "        \n",
    "        y_pred = torch.cat([torch.sum(torch.mul(u_emb, i_emb), 1) + i_b, torch.sum(torch.mul(u_emb, j_emb), 1) + j_b], dim=0)\n",
    "        y_true = torch.cat([torch.ones(100), torch.zeros(100)], dim=0)\n",
    "        \n",
    "        return u, i, j, mf_auc, user_embedding, item_embedding, item_bias, y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ToTensor(data):\n",
    "    return torch.LongTensor(data).cuda()\n",
    "\n",
    "def train(train_data, model, opt, learning_rate):\n",
    "    \n",
    "    loss = model(ToTensor(train_data))\n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "batch_size = 50\n",
    "learning_rate = 0.01\n",
    "bpr = BPR(num_user, num_item, 50).cuda()\n",
    "\n",
    "test_ratings = generate_test(user_ratings)\n",
    "\n",
    "optimizer = torch.optim.Adagrad(bpr.parameters(), lr=0.025)\n",
    "\n",
    "for epoch in range(1, 21):\n",
    "    batch_loss = 0\n",
    "    for k in range(1, 10000):\n",
    "        train_data = train_batch(user_ratings, test_ratings, num_item, batch_size)\n",
    "        loss = train(train_data, bpr, optimizer, learning_rate)\n",
    "        batch_loss += loss\n",
    "        \n",
    "    print(\"epoch: %d\"%epoch)\n",
    "    print(\"loss: \",batch_loss.item()/k)\n",
    "    auc_sum = 0\n",
    "    for uij, uij_list in test_batch(user_ratings, test_ratings, num_item):\n",
    "        u, i, j, auc, user_embedding, item_embedding, item_bias, y_pred, y_true = bpr.evalu(ToTensor(uij))\n",
    "        auc = metrics.roc_auc_score(y_true.cpu().numpy(), y_pred.cpu().detach().numpy())\n",
    "        auc_sum += auc\n",
    "    print(\"auc: \", auc_sum.item()/num_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
